name: Auto Scrape WaterLevel

on:
  schedule:
    - cron: '0 13 * * *'
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      TZ: Asia/Bangkok
      CSV_OUT: waterlevel_report.csv
      ENABLE_GOOGLE_DRIVE_UPLOAD: "false"   # ปิดอัปโหลดในตัวสคริปต์

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Setup Google Chrome
        id: chrome
        uses: browser-actions/setup-chrome@v1

      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip
          pip install \
            selenium==4.23.1 \
            pandas==2.2.2 \
            google-api-python-client==2.137.0 \
            google-auth==2.35.0 \
            google-auth-httplib2==0.2.0

      - name: Run scraper
        env:
          # ใช้ path ของ Chrome จาก step ข้างบน
          GOOGLE_CHROME_BIN: ${{ steps.chrome.outputs.chrome-path }}
          CSV_OUT: ${{ env.CSV_OUT }}
        run: |
          python scrap2.py   # ← ถ้าไฟล์ชื่ออื่น แก้ให้ตรง

      - name: Append & Upload CSV to Google Drive (Shared Drive)
        if: ${{ secrets.PURIPAT_ID != '' && secrets.SERVICE_ACCOUNT != '' }}
        env:
          DRIVE_FOLDER_ID: ${{ secrets.PURIPAT_ID }}
          SERVICE_ACCOUNT_JSON: ${{ secrets.SERVICE_ACCOUNT }}
          CSV_OUT: ${{ env.CSV_OUT }}
        run: |
          python - <<'PY'
          import os, io, json, sys
          import pandas as pd
          from google.oauth2.service_account import Credentials
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload

          CSV_OUT = os.getenv("CSV_OUT", "waterlevel_report.csv")
          FOLDER_ID = os.environ["DRIVE_FOLDER_ID"]
          SA_JSON = os.environ["SERVICE_ACCOUNT_JSON"]

          if not os.path.exists(CSV_OUT):
              print(f"❌ Not found local CSV: {CSV_OUT}", file=sys.stderr); sys.exit(1)

          info = json.loads(SA_JSON)
          creds = Credentials.from_service_account_info(info, scopes=["https://www.googleapis.com/auth/drive"])
          drive = build("drive", "v3", credentials=creds, cache_discovery=False)

          drive.files().get(fileId=FOLDER_ID, fields="id,name,driveId", supportsAllDrives=True).execute()

          fname = os.path.basename(CSV_OUT).replace("'", "\\'")
          q = f"name = '{fname}' and '{FOLDER_ID}' in parents and trashed = false"
          res = drive.files().list(
              q=q, fields="files(id,name,mimeType)",
              supportsAllDrives=True, includeItemsFromAllDrives=True
          ).execute()
          files = res.get("files", [])

          new_df = pd.read_csv(CSV_OUT, encoding="utf-8-sig")

          if files:
              fid = files[0]["id"]
              mime = files[0]["mimeType"]
              if mime.startswith("application/vnd.google-apps"):
                  print("❌ ปลายทางเป็น Google Sheets; ต้องใช้ Sheets API", file=sys.stderr)
                  sys.exit(2)

              request = drive.files().get_media(fileId=fid)
              fh = io.BytesIO()
              downloader = MediaIoBaseDownload(fh, request)
              done = False
              while not done:
                  status, done = downloader.next_chunk()
              fh.seek(0)
              try:
                  old_df = pd.read_csv(fh, encoding="utf-8-sig")
              except Exception:
                  fh.seek(0)
                  old_df = pd.read_csv(fh)

              all_df = pd.concat([old_df, new_df], ignore_index=True)

              key_opts = [
                  ['ชื่อสถานี', 'เวลา', 'วันที่เก็บข้อมูล'],
                  ['ชื่อสถานี', 'ที่ตั้ง', 'เวลา', 'วันที่เก็บข้อมูล'],
              ]
              used = None
              for keys in key_opts:
                  if set(keys).issubset(all_df.columns):
                      all_df.drop_duplicates(subset=keys, keep='last', inplace=True)
                      used = keys
                      break
              if not used:
                  all_df.drop_duplicates(keep='last', inplace=True)

              if {'วันที่เก็บข้อมูล','เวลา'}.issubset(all_df.columns):
                  try:
                      dt = pd.to_datetime(all_df['วันที่เก็บข้อมูล'] + ' ' + all_df['เวลา'], errors='coerce', dayfirst=True)
                      all_df.insert(0, 'DateTime', dt)
                      all_df.sort_values('DateTime', inplace=True)
                  except Exception:
                      pass

              tmp_path = "__merged_out.csv"
              all_df.to_csv(tmp_path, index=False, encoding="utf-8-sig")

              media = MediaFileUpload(tmp_path, mimetype="text/csv", resumable=True)
              drive.files().update(fileId=fid, media_body=media, supportsAllDrives=True).execute()
              print(f"✅ Appended & updated: {fname} (fileId={fid})")
          else:
              meta = {"name": os.path.basename(CSV_OUT), "parents": [FOLDER_ID]}
              media = MediaFileUpload(CSV_OUT, mimetype="text/csv", resumable=True)
              created = drive.files().create(
                  body=meta, media_body=media, fields="id", supportsAllDrives=True
              ).execute()
              print(f"✅ Created new: {CSV_OUT} (fileId={created['id']})")
          PY

      - name: Upload CSV as Artifact (backup)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: waterlevel_csv
          path: waterlevel_report.csv
