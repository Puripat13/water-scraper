# -*- coding: utf-8 -*-
import os, time, re, sys
from datetime import datetime
import pandas as pd

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

URL = "https://nationalthaiwater.onwr.go.th/waterlevel"
CSV_OUT = "waterlevel_report.csv"
WAIT = 30

def make_driver():
    opt = Options()
    opt.page_load_strategy = "eager"
    opt.add_argument("--headless=new")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument("--disable-gpu")
    opt.add_argument("--window-size=1366,800")
    opt.add_argument("--disable-blink-features=AutomationControlled")
    opt.add_argument("--lang=th-TH,th")
    opt.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    )
    drv = webdriver.Chrome(options=opt)
    drv.set_page_load_timeout(60)
    return drv

def pick_richest_table_locator(driver):
    """‡∏•‡∏≠‡∏á‡∏ó‡∏∏‡∏Å selector ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß '‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î'"""
    candidates = [
        (By.CSS_SELECTOR, "div.MuiDataGrid-virtualScrollerRenderZone .MuiDataGrid-row"),
        (By.CSS_SELECTOR, "div[role='rowgroup'] [role='row']"),
        (By.CSS_SELECTOR, ".MuiTable-root tbody tr"),
        (By.CSS_SELECTOR, "table tbody tr"),
    ]
    best = None
    best_n = -1
    for by, sel in candidates:
        try:
            WebDriverWait(driver, 8).until(EC.presence_of_element_located((by, sel)))
        except TimeoutException:
            continue
        rows = driver.find_elements(by, sel)
        n = len(rows)
        if n > best_n:
            best_n = n
            best = (by, sel)
    if not best:
        raise TimeoutException("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤")
    print(f"[INFO] ‡πÉ‡∏ä‡πâ locator: {best} (‡πÅ‡∏ñ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô {best_n})")
    return best

def set_rows_per_page_100(driver):
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏±‡πâ‡∏á Rows per page = 100 (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)"""
    try:
        # MUI pagination select
        # ‡∏´‡∏≤ select ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ 10/25/50/100
        options_xpath = "//ul//li[normalize-space(.)='100']"
        # ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏°‡∏ô‡∏π page size
        triggers = driver.find_elements(By.XPATH, "//div[contains(@class,'MuiTablePagination') or contains(@class,'MuiDataGrid')]//div[contains(@class,'MuiSelect-select') or @role='button']")
        for trg in triggers:
            try:
                driver.execute_script("arguments[0].click();", trg)
                time.sleep(0.3)
                items = driver.find_elements(By.XPATH, options_xpath)
                if items:
                    driver.execute_script("arguments[0].click();", items[0])
                    print("[INFO] ‡∏ï‡∏±‡πâ‡∏á Rows per page = 100")
                    time.sleep(0.6)
                    return
            except Exception:
                continue
    except Exception:
        pass

def find_next_btn(driver):
    xps = [
        "//button[@aria-label='Next page' and not(@disabled)]",
        "//span[@title='Next Page']/button[not(@disabled)]",
        "//button[not(@disabled) and (contains(., '‡∏ñ‡∏±‡∏î‡πÑ‡∏õ') or contains(., 'Next'))]",
        "//button[not(@disabled) and .//*[local-name()='svg' or local-name()='path']]",
    ]
    for xp in xps:
        els = driver.find_elements(By.XPATH, xp)
        for el in els:
            try:
                if el.is_enabled() and el.is_displayed():
                    return el
            except Exception:
                continue
    css = [
        "button[aria-label='Next page']:not([disabled])",
        "span[title='Next Page'] > button:not([disabled])",
    ]
    for sel in css:
        els = driver.find_elements(By.CSS_SELECTOR, sel)
        for el in els:
            try:
                if el.is_enabled() and el.is_displayed():
                    return el
            except Exception:
                continue
    return None

def extract_cells_from_row(row):
    tds = row.find_elements(By.CSS_SELECTOR, "td")
    if not tds:
        tds = row.find_elements(By.CSS_SELECTOR, "[role='gridcell']")
    return [c.text.strip() for c in tds if c.text is not None]

def get_rows(driver, locator):
    by, sel = locator
    rows_el = driver.find_elements(by, sel)
    rows = []
    for r in rows_el:
        cols = extract_cells_from_row(r)
        if cols:
            rows.append(cols)
    return rows

def extract_thai(text):
    if pd.isna(text) or text is None:
        return ""
    m = re.search(r"[‡∏Å-‡πô].*", str(text))
    return m.group(0).strip() if m else str(text).strip()

def scrape():
    d = make_driver()
    t0 = time.time()
    try:
        print(f"[INFO] ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤: {URL}")
        d.get(URL)

        # ‡∏£‡∏≠‡∏à‡∏ô‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤
        WebDriverWait(d, WAIT).until(EC.presence_of_element_located((By.XPATH, "//*")))
        time.sleep(1.0)

        locator = pick_richest_table_locator(d)
        set_rows_per_page_100(d)

        all_rows = []
        curdate = datetime.today().strftime("%d/%m/%Y")
        page = 1

        while True:
            time.sleep(1.0)
            rows = get_rows(d, locator)
            print(f"[INFO] Page {page}: ‡∏û‡∏ö {len(rows)} ‡πÅ‡∏ñ‡∏ß")
            for r in rows:
                # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö 9 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                r = (r + [""] * 9)[:9]
                r[-1] = curdate  # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                all_rows.append(r)

            nxt = find_next_btn(d)
            if not nxt:
                print("[INFO] ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏°‡∏ñ‡∏±‡∏î‡πÑ‡∏õ -> ‡∏à‡∏ö")
                break
            try:
                d.execute_script("arguments[0].click();", nxt)
                page += 1
                WebDriverWait(d, 10).until(lambda x: len(get_rows(x, locator)) > 0)
            except Exception as e:
                print(f"[WARN] ‡∏Å‡∏î‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e} -> ‡∏à‡∏ö")
                break

        return all_rows, t0
    finally:
        d.quit()

def save_csv(rows):
    if not rows:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return
    headers = [
        "‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ","‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á","‡πÄ‡∏ß‡∏•‡∏≤","‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡πâ‡∏≥",
        "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏•‡∏¥‡πà‡∏á","‡∏Ñ‡πà‡∏≤‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÄ‡∏™‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö","%‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏∏‡∏ô‡πâ‡∏≥",
        "‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå","‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    ]
    fixed = []
    for r in rows:
        r = (list(r) + [""] * 9)[:9]
        fixed.append(r)
    df = pd.DataFrame(fixed, columns=headers)
    df["‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ"] = df["‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ"].apply(extract_thai)

    # ‡∏Å‡∏±‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ ‚Äì ‡∏´‡∏£‡∏∑‡∏≠ '-' ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
    df = df.replace({"-": "", "‚Äì": ""})

    file_exists = os.path.exists(CSV_OUT)
    df.to_csv(CSV_OUT, mode="a", index=False, encoding="utf-8-sig", header=not file_exists)
    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {len(df)} ‡πÅ‡∏ñ‡∏ß -> {CSV_OUT}")

def main():
    try:
        rows, t0 = scrape()
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å keep ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ (‡∏Å‡∏±‡∏ô header ‡πÅ‡∏ù‡∏á)
        rows = [r for r in rows if re.search(r"[‡∏Å-‡πô]", r[0] if r else "")]
        save_csv(rows)
        print(f"‚è± ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {time.time()-t0:.2f}s")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
