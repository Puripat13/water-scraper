# -*- coding: utf-8 -*-
# https://nationalthaiwater.onwr.go.th/dam ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥

import os, time
import pandas as pd
from datetime import datetime

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException

URL = "https://nationalthaiwater.onwr.go.th/dam"

# ---------- Chrome / Selenium ----------
def make_driver():
    opt = Options()
    opt.add_argument("--headless=new")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument("--window-size=1366,900")
    opt.add_argument("--disable-gpu")
    opt.add_argument("--lang=th-TH")
    return webdriver.Chrome(options=opt)  # Selenium Manager ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ö‡∏ô‡∏≤‡∏£‡∏µ‡πÉ‡∏´‡πâ

def wait_table_ready(driver, timeout=20):
    # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏°‡∏µ‡πÅ‡∏ñ‡∏ß ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ overlay ‡∏ö‡∏±‡∏á
    WebDriverWait(driver, timeout).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, ".MuiTable-root tbody tr"))
    )
    try:
        WebDriverWait(driver, 5).until_not(
            EC.presence_of_element_located((By.CLASS_NAME, "MuiBackdrop-root"))
        )
    except TimeoutException:
        pass

def click_medium_tab(driver, timeout=20):
    """
    ‡πÑ‡∏õ‡πÅ‡∏ó‡πá‡∏ö '‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á' ‡πÅ‡∏ö‡∏ö‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô:
    - ‡πÉ‡∏ä‡πâ aria-controls (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö text() ‡∏ï‡∏£‡∏á ‡πÜ)
    - scrollIntoView + JS click fallback
    """
    xp = "//button[@aria-controls='tabpanel-1']"
    el = WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.XPATH, xp)))
    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", el)
    try:
        WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, xp)))
        el.click()
    except (ElementClickInterceptedException, TimeoutException):
        driver.execute_script("arguments[0].click();", el)

def click_next_page(driver, timeout=6):
    """
    ‡∏Ñ‡∏•‡∏¥‡∏Å next page ‡∏ñ‡πâ‡∏≤‡πÑ‡∏õ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
    return: True=‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà, False=‡∏™‡∏∏‡∏î‡∏´‡∏ô‡πâ‡∏≤/‡∏Ñ‡∏•‡∏¥‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
    """
    try:
        btn = WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.XPATH, "//span[@title='Next Page']/button"))
        )
        # ‡∏ñ‡πâ‡∏≤‡∏õ‡∏∏‡πà‡∏° disable ‡∏ó‡∏µ‡πà aria-disabled=true ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î
        disabled = btn.get_attribute("aria-disabled")
        if disabled in ("true", True):
            return False
        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btn)
        try:
            WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, "//span[@title='Next Page']/button")))
            btn.click()
        except (ElementClickInterceptedException, TimeoutException):
            driver.execute_script("arguments[0].click();", btn)
        return True
    except TimeoutException:
        return False

# ---------- Scrape core ----------
def scrape_current_tab(driver, tab_label):
    """
    ‡∏î‡∏∂‡∏á‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ list of rows (‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ó‡πá‡∏ö‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    """
    all_data, page = [], 1
    current_date = datetime.today().strftime("%d/%m/%Y")

    while True:
        wait_table_ready(driver, timeout=20)
        time.sleep(0.8)  # ‡∏Å‡∏±‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏î‡πâ‡∏á re-render

        rows = driver.find_elements(By.CSS_SELECTOR, ".MuiTable-root tbody tr")
        count_before = len(all_data)

        for r in rows:
            cols = [td.text.strip() for td in r.find_elements(By.CSS_SELECTOR, "td")]
            if any(c not in ("", "-", None) for c in cols):
                cols += [current_date, tab_label]
                all_data.append(cols)

        new_rows = len(all_data) - count_before
        print(f"[{tab_label}] page {page}: +{new_rows} rows")

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏ï‡πà‡∏≠ -> break
        if not click_next_page(driver):
            print(f"[{tab_label}] reached last page.")
            break

        page += 1
        time.sleep(0.6)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏´‡∏ô‡πâ‡∏≤

    return all_data

def save_data_to_csv(data, dam_type):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV ‡∏ó‡∏µ‡πà root:
      - waterdam_report_large.csv
      - waterdam_report_medium.csv
    ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ñ‡∏ß = ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö + [Data_Time, Water_Type] ‡∏î‡πâ‡∏≤‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°: append ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢ (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô)
    """
    if not data:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {dam_type}, ‡∏Ç‡πâ‡∏≤‡∏°")
        return

    path = f"waterdam_report_{dam_type}.csv"
    exists = os.path.exists(path)

    df = pd.DataFrame(data)
    df.replace("", pd.NA, inplace=True)
    df.dropna(axis=1, how="all", inplace=True)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
    if exists:
        with open(path, encoding="utf-8-sig") as f:
            first_line = f.readline()
        old_cols = len(first_line.strip().split(","))
        if old_cols != df.shape[1]:
            print(f"‚ö†Ô∏è ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏° ({old_cols} ‚â† {df.shape[1]}). ‡∏à‡∏∞‡πÑ‡∏°‡πà append ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô")
            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà (‡∏ó‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°) ‚Äî ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å ‚Äú‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏î‡∏¥‡∏°‚Äù ‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏ó‡∏≥‡πÉ‡∏ô scrap4.py ‡∏ï‡∏≠‡∏ô‡∏£‡∏ß‡∏°‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ
            exists = False

    df.to_csv(path, mode=("a" if exists else "w"),
              index=False, encoding="utf-8-sig", header=not exists)
    print(f"üíæ saved {path} (+{len(df)} rows)")

# ---------- Main ----------
def main():
    t0 = time.time()
    driver = make_driver()
    driver.get(URL)

    # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å‡∏û‡∏£‡πâ‡∏≠‡∏°
    wait_table_ready(driver, timeout=25)

    # 1) ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å)
    large_rows = scrape_current_tab(driver, "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà")
    save_data_to_csv(large_rows, "large")

    # 2) ‡πÑ‡∏õ‡πÅ‡∏ó‡πá‡∏ö '‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á'
    click_medium_tab(driver)
    wait_table_ready(driver, timeout=20)

    medium_rows = scrape_current_tab(driver, "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á")
    save_data_to_csv(medium_rows, "medium")

    driver.quit()
    print(f"‚è±Ô∏è ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {time.time() - t0:.2f}s")

if __name__ == "__main__":
    main()
