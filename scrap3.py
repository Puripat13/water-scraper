# https://nationalthaiwater.onwr.go.th/dam ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥

import os
import time
import base64
import json
import requests
from datetime import datetime

import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options

# =====================[ CONFIG | GitHub Upload ]=====================
GITHUB_UPLOAD   = os.environ.get("GITHUB_UPLOAD", "false").lower() == "true"
GITHUB_TOKEN    = os.environ.get("GITHUB_TOKEN", "")             # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ñ‡πâ‡∏≤ GITHUB_UPLOAD=true
GITHUB_REPO     = os.environ.get("GITHUB_REPO", "Puripat13/water-scraper")
GITHUB_BRANCH   = os.environ.get("GITHUB_BRANCH", "main")
GITHUB_DEST_DIR = os.environ.get("GITHUB_DEST_DIR", "").strip("/")  # e.g. "data" ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏á = root
COMMIT_AUTHOR   = os.environ.get("GIT_AUTHOR", "github-actions[bot]")
COMMIT_EMAIL    = os.environ.get("GIT_EMAIL", "github-actions[bot]@users.noreply.github.com")

def _gh_api(path: str) -> str:
    return f"https://api.github.com/repos/{GITHUB_REPO}/contents/{path}"

def upload_to_github(local_path: str, dest_path_in_repo: str, message: str):
    """
    ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î/‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏á GitHub Repo ‡∏ú‡πà‡∏≤‡∏ô Contents API
    - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô SHA ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ update
    """
    if not os.path.exists(local_path):
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {local_path} ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        return

    with open(local_path, "rb") as f:
        content_b64 = base64.b64encode(f.read()).decode()

    headers = {"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {}
    url = _gh_api(dest_path_in_repo)

    # ‡∏´‡∏≤ SHA ‡πÄ‡∏î‡∏¥‡∏° (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠ update
    sha = None
    get_res = requests.get(url, headers=headers, params={"ref": GITHUB_BRANCH})
    if get_res.status_code == 200:
        try:
            sha = get_res.json().get("sha")
        except Exception:
            sha = None

    payload = {
        "message": message,
        "content": content_b64,
        "branch": GITHUB_BRANCH,
        "committer": {"name": COMMIT_AUTHOR, "email": COMMIT_EMAIL},
    }
    if sha:
        payload["sha"] = sha

    put_res = requests.put(url, headers=headers, data=json.dumps(payload))
    if put_res.status_code in (200, 201):
        action = "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï" if sha else "‡∏™‡∏£‡πâ‡∏≤‡∏á"
        print(f"‚úÖ {action}‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô GitHub: {dest_path_in_repo}")
    else:
        print(f"‚ùå ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {dest_path_in_repo} -> {put_res.status_code} {put_res.text}")

# =====================[ Scraper ]=====================
options = Options()
options.add_argument('--headless=new')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--window-size=1366,840')

driver = webdriver.Chrome(options=options)
driver.get('https://nationalthaiwater.onwr.go.th/dam')

WebDriverWait(driver, 15).until(
    EC.presence_of_element_located((By.CSS_SELECTOR, ".MuiTable-root tbody tr"))
)

start_time = time.time()  # üëâ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° scrape

def scrape_data(tab_name):
    all_data = []
    current_date = datetime.today().strftime("%d/%m/%Y")
    page = 1

    print(f"\n‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {tab_name}")

    while True:
        time.sleep(2)
        rows = driver.find_elements(By.CSS_SELECTOR, ".MuiTable-root tbody tr")
        count_before = len(all_data)

        for row in rows:
            cols = [col.text.strip() for col in row.find_elements(By.CSS_SELECTOR, "td")]
            # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÜ
            if any(col not in ("", "-", None) for col in cols):
                cols += [current_date, tab_name]
                all_data.append(cols)

        count_after = len(all_data)
        scraped_this_page = count_after - count_before
        print(f"‡∏´‡∏ô‡πâ‡∏≤ {page}: ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß {scraped_this_page} ‡πÅ‡∏ñ‡∏ß")

        try:
            next_button = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, "//span[@title='Next Page']/button"))
            )
            if next_button.is_enabled():
                driver.execute_script("arguments[0].click();", next_button)
                page += 1
                print(f"‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏´‡∏ô‡πâ‡∏≤ {page}...")
                time.sleep(2)
            else:
                print(f"‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {tab_name}")
                break
        except:
            print(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏∏‡πà‡∏° 'Next Page' ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {tab_name}")
            break

    return all_data

def save_data_to_csv(data, dam_type):
    if not data:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {dam_type} ‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå")
        return None

    file_path = f"waterdam_report_{dam_type}.csv"
    file_exists = os.path.exists(file_path)

    df = pd.DataFrame(data)

    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡∏¢ + ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÄ‡∏ö‡∏≤ ‡πÜ
    df.replace("", pd.NA, inplace=True)
    df.dropna(axis=1, how='all', inplace=True)

    new_num_cols = df.shape[1]

    if file_exists:
        with open(file_path, encoding="utf-8-sig") as f:
            first_line = f.readline()
            existing_cols = len(first_line.strip().split(","))
        if existing_cols != new_num_cols:
            print(f"‚ö†Ô∏è ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏° ({existing_cols} ‚â† {new_num_cols}) ‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {dam_type}")
            return None

    df.to_csv(file_path, mode='a', index=False, encoding="utf-8-sig", header=not file_exists)
    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {dam_type} ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå {file_path} ‡πÅ‡∏•‡πâ‡∏ß ({len(df)} ‡πÅ‡∏ñ‡∏ß)")

    return file_path

# ========= ‡∏î‡∏∂‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà =========
large_dam_data = scrape_data("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà")

# ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÅ‡∏ó‡πá‡∏ö '‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á' ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
medium_tab_button = WebDriverWait(driver, 15).until(
    EC.presence_of_element_located((By.XPATH, "//button[@aria-controls='tabpanel-1']"))
)

# ‡∏£‡∏≠‡πÉ‡∏´‡πâ overlay (‡πÄ‡∏ä‡πà‡∏ô loading screen) ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å
try:
    WebDriverWait(driver, 10).until_not(
        EC.presence_of_element_located((By.CLASS_NAME, "MuiBackdrop-root"))
    )
except:
    pass

# Scroll ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
driver.execute_script("arguments[0].scrollIntoView(true);", medium_tab_button)
time.sleep(1)
driver.execute_script("arguments[0].click();", medium_tab_button)

WebDriverWait(driver, 10).until(
    EC.presence_of_element_located((By.CSS_SELECTOR, ".MuiTable-root tbody tr"))
)

# ========= ‡∏î‡∏∂‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á =========
medium_dam_data = scrape_data("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á")

# ========= ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV =========
large_csv  = save_data_to_csv(large_dam_data, "large")
medium_csv = save_data_to_csv(medium_dam_data, "medium")

driver.quit()
end_time = time.time()  # üëâ ‡∏´‡∏•‡∏±‡∏á quit()
print(f"‚è±Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

# =====================[ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ GitHub Repo ]=====================
if GITHUB_UPLOAD and GITHUB_TOKEN:
    dest_dir = f"{GITHUB_DEST_DIR}/" if GITHUB_DEST_DIR else ""
    if large_csv:
        upload_to_github(
            local_path=large_csv,
            dest_path_in_repo=f"{dest_dir}{os.path.basename(large_csv)}",
            message="Update dam water (large) CSV [skip ci]"
        )
    if medium_csv:
        upload_to_github(
            local_path=medium_csv,
            dest_path_in_repo=f"{dest_dir}{os.path.basename(medium_csv)}",
            message="Update dam water (medium) CSV [skip ci]"
        )
else:
    print("‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ GitHub (‡∏ï‡∏±‡πâ‡∏á GITHUB_UPLOAD=true ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà GITHUB_TOKEN ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)")
